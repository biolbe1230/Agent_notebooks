{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982f10ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "# sk-1feb7ffcf87f43a2a3feb12cc8349348\n",
    "_set_env(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "# 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\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm = init_chat_model(\"deepseek-chat\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc92d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_4a4dab67-3874-48b7-99f2-f31c740b74cf)\n",
      " Call ID: call_0_4a4dab67-3874-48b7-99f2-f31c740b74cf\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://langchain-ai.github.io/langgraph/tutorials/introduction/\", \"title\": \"LangGraph Quickstart - GitHub Pages\", \"content\": \"[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-9-1)Assistant: LangGraph is a library designed to help build stateful multi-agent applications using language models. It provides tools for creating workflows and state machines to coordinate multiple AI agents or language model interactions. LangGraph is built on top of LangChain, leveraging its components while adding graph-based coordination capabilities. It's particularly useful for developing more complex, [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-6)   LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It's particularly useful for creating agent and multi-agent workflows.\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-7)\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-21-8)2. Developer: [...] [](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-19)LangGraph is likely a framework or library designed specifically for creating AI agents with advanced capabilities. Here are a few points to consider based on this recommendation:\\n[](https://langchain-ai.github.io/langgraph/tutorials/introduction/#__codelineno-48-20)\", \"score\": 0.9328032, \"raw_content\": null}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs.\", \"content\": \"LangGraph — used by Replit, Uber, LinkedIn, GitLab and more — is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\n\\n```\\npip install -U langgraph\\n```\", \"score\": 0.8884594, \"raw_content\": null}], \"response_time\": 1.94}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here's what I found about LangGraph:\n",
      "\n",
      "1. **LangGraph Quickstart - GitHub Pages**:\n",
      "   - LangGraph is a library designed for building stateful, multi-actor applications with Large Language Models (LLMs). It helps create workflows and state machines to coordinate multiple AI agents or language model interactions.\n",
      "   - It is built on top of LangChain and adds graph-based coordination capabilities, making it useful for complex, multi-agent workflows.\n",
      "   - [Read more here](https://langchain-ai.github.io/langgraph/tutorials/introduction/).\n",
      "\n",
      "2. **GitHub Repository**:\n",
      "   - LangGraph is described as a low-level orchestration framework for building controllable agents. It is used by companies like Replit, Uber, LinkedIn, and GitLab.\n",
      "   - It provides customizable architectures, long-term memory, and human-in-the-loop features to handle complex tasks reliably.\n",
      "   - You can install it via pip: `pip install -U langgraph`.\n",
      "   - [Check out the GitHub repo](https://github.com/langchain-ai/langgraph).\n",
      "\n",
      "Would you like more details on any specific aspect of LangGraph?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5ed705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! LangGraph is well-suited for building autonomous agents, especially those involving multi-agent workflows or stateful interactions. Here’s how you can get started and some ideas for your project:\n",
      "\n",
      "---\n",
      "\n",
      "### **Steps to Build an Autonomous Agent with LangGraph**\n",
      "1. **Install LangGraph**:\n",
      "   ```bash\n",
      "   pip install -U langgraph\n",
      "   ```\n",
      "\n",
      "2. **Understand the Core Concepts**:\n",
      "   - **State Machines**: LangGraph uses graph-based workflows to model agent behavior. You define nodes (agents or tasks) and edges (transitions between nodes).\n",
      "   - **Multi-Agent Coordination**: You can design agents to collaborate or compete, passing messages or states between them.\n",
      "   - **Memory**: LangGraph supports long-term memory, which is useful for agents that need to remember past interactions.\n",
      "\n",
      "3. **Define Your Agent's Workflow**:\n",
      "   - Break down the agent's tasks into smaller steps (nodes).\n",
      "   - Use edges to define how the agent transitions between steps based on conditions or inputs.\n",
      "\n",
      "4. **Integrate with LLMs**:\n",
      "   - LangGraph works seamlessly with LangChain, so you can use LLMs (like OpenAI, Anthropic, or local models) to power your agent's decision-making.\n",
      "\n",
      "5. **Add Human-in-the-Loop (Optional)**:\n",
      "   - You can design your agent to pause and ask for human input when uncertain or when specific conditions are met.\n",
      "\n",
      "---\n",
      "\n",
      "### **Project Ideas**\n",
      "1. **Autonomous Research Assistant**:\n",
      "   - An agent that can search the web, summarize findings, and generate reports.\n",
      "   - Use LangGraph to manage the workflow: search → summarize → refine → output.\n",
      "\n",
      "2. **Multi-Agent Debate System**:\n",
      "   - Build multiple agents with different personas (e.g., optimist, pessimist) and let them debate a topic.\n",
      "   - Use LangGraph to moderate the debate and synthesize conclusions.\n",
      "\n",
      "3. **Task Automation Agent**:\n",
      "   - An agent that can perform tasks like scheduling, email drafting, or data analysis.\n",
      "   - Use LangGraph to handle conditional workflows (e.g., \"If the email is urgent, send it immediately; else, draft a response\").\n",
      "\n",
      "4. **Game NPCs with Memory**:\n",
      "   - Create non-player characters (NPCs) for a game that remember player interactions and adapt their behavior over time.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Code Snippet**\n",
      "Here’s a simple example of defining a workflow for an autonomous agent:\n",
      "```python\n",
      "from langgraph.graph import Graph\n",
      "from langchain.llms import OpenAI\n",
      "\n",
      "# Define nodes (tasks)\n",
      "def research_topic(state):\n",
      "    llm = OpenAI()\n",
      "    research = llm(f\"Research the topic: {state['topic']}\")\n",
      "    return {\"research\": research}\n",
      "\n",
      "def summarize_research(state):\n",
      "    llm = OpenAI()\n",
      "    summary = llm(f\"Summarize this: {state['research']}\")\n",
      "    return {\"summary\": summary}\n",
      "\n",
      "# Create the graph\n",
      "workflow = Graph()\n",
      "workflow.add_node(\"research\", research_topic)\n",
      "workflow.add_node(\"summarize\", summarize_research)\n",
      "workflow.add_edge(\"research\", \"summarize\")  # Research -> Summarize\n",
      "workflow.set_entry_point(\"research\")\n",
      "\n",
      "# Run the workflow\n",
      "result = workflow.run({\"topic\": \"climate change\"})\n",
      "print(result[\"summary\"])\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Next Steps**\n",
      "- Explore the [LangGraph documentation](https://langchain-ai.github.io/langgraph/tutorials/introduction/) for more examples.\n",
      "- Join the [LangChain community](https://discord.gg/langchain) for support and ideas.\n",
      "- Start small and iterate—autonomous agents can get complex quickly!\n",
      "\n",
      "Let me know if you'd like help with a specific part of your project!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f48dc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58025bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f02c807-6fa9-61de-8006-45bb4ed20cbd'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae51bd3",
   "metadata": {},
   "source": [
    "直接使用to_replay.config即可加载对话，注意是重新运行replay这个节点，而不是replay.next（毕竟next是null了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b47c009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! LangGraph is well-suited for building autonomous agents, especially those involving multi-agent workflows or stateful interactions. Here’s how you can get started and some ideas for your project:\n",
      "\n",
      "---\n",
      "\n",
      "### **Steps to Build an Autonomous Agent with LangGraph**\n",
      "1. **Install LangGraph**:\n",
      "   ```bash\n",
      "   pip install -U langgraph\n",
      "   ```\n",
      "\n",
      "2. **Understand the Core Concepts**:\n",
      "   - **State Machines**: LangGraph uses graph-based workflows to model agent behavior. You define nodes (agents or tasks) and edges (transitions between nodes).\n",
      "   - **Multi-Agent Coordination**: You can design agents to collaborate or compete, passing messages or states between them.\n",
      "   - **Memory**: LangGraph supports long-term memory, which is useful for agents that need to remember past interactions.\n",
      "\n",
      "3. **Define Your Agent's Workflow**:\n",
      "   - Break down the agent's tasks into smaller steps (nodes).\n",
      "   - Use edges to define how the agent transitions between steps based on conditions or inputs.\n",
      "\n",
      "4. **Integrate with LLMs**:\n",
      "   - LangGraph works seamlessly with LangChain, so you can use LLMs (like OpenAI, Anthropic, or local models) to power your agent's decision-making.\n",
      "\n",
      "5. **Add Human-in-the-Loop (Optional)**:\n",
      "   - You can design your agent to pause and ask for human input when uncertain or when specific conditions are met.\n",
      "\n",
      "---\n",
      "\n",
      "### **Project Ideas**\n",
      "1. **Autonomous Research Assistant**:\n",
      "   - An agent that can search the web, summarize findings, and generate reports.\n",
      "   - Use LangGraph to manage the workflow: search → summarize → refine → output.\n",
      "\n",
      "2. **Multi-Agent Debate System**:\n",
      "   - Build multiple agents with different personas (e.g., optimist, pessimist) and let them debate a topic.\n",
      "   - Use LangGraph to moderate the debate and synthesize conclusions.\n",
      "\n",
      "3. **Task Automation Agent**:\n",
      "   - An agent that can perform tasks like scheduling, email drafting, or data analysis.\n",
      "   - Use LangGraph to handle conditional workflows (e.g., \"If the email is urgent, send it immediately; else, draft a response\").\n",
      "\n",
      "4. **Game NPCs with Memory**:\n",
      "   - Create non-player characters (NPCs) for a game that remember player interactions and adapt their behavior over time.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Code Snippet**\n",
      "Here’s a simple example of defining a workflow for an autonomous agent:\n",
      "```python\n",
      "from langgraph.graph import Graph\n",
      "from langchain.llms import OpenAI\n",
      "\n",
      "# Define nodes (tasks)\n",
      "def research_topic(state):\n",
      "    llm = OpenAI()\n",
      "    research = llm(f\"Research the topic: {state['topic']}\")\n",
      "    return {\"research\": research}\n",
      "\n",
      "def summarize_research(state):\n",
      "    llm = OpenAI()\n",
      "    summary = llm(f\"Summarize this: {state['research']}\")\n",
      "    return {\"summary\": summary}\n",
      "\n",
      "# Create the graph\n",
      "workflow = Graph()\n",
      "workflow.add_node(\"research\", research_topic)\n",
      "workflow.add_node(\"summarize\", summarize_research)\n",
      "workflow.add_edge(\"research\", \"summarize\")  # Research -> Summarize\n",
      "workflow.set_entry_point(\"research\")\n",
      "\n",
      "# Run the workflow\n",
      "result = workflow.run({\"topic\": \"climate change\"})\n",
      "print(result[\"summary\"])\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### **Next Steps**\n",
      "- Explore the [LangGraph documentation](https://langchain-ai.github.io/langgraph/tutorials/introduction/) for more examples.\n",
      "- Join the [LangChain community](https://discord.gg/langchain) for support and ideas.\n",
      "- Start small and iterate—autonomous agents can get complex quickly!\n",
      "\n",
      "Let me know if you'd like help with a specific part of your project!\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
